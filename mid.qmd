---
title: "Characterizing Automobiles"
author: "Andrew Cerqui"
date: "03/21/2025"

format: 
  html:  # You will quite likely want to change all but the last one, to taste
    theme:
        light: flatly
        dark: darkly
    mainfont: monospace
    highlight-style: github
    title-block-banner: true
    embed-resources: true
---

# Setup

-   Setup

```{r libs}
sh <- suppressPackageStartupMessages
sh(library(tidyverse))
sh(library(caret))
sh(library(fastDummies))
sh(library(class))
sh(library(ISLR)) # for the "Auto" dataframe
sh(library(moderndive))
sh(library(pROC))
```

# Dataframe

-   We use the `Auto` dataframe.

```{r df}
head(Auto)
```

-   It has the following variable names, which describe various attributes of automobiles.

```{r df2}
names(Auto)
```

# Multiple Regression

-   Run a linear regression model with `mpg` as the dependent variable and `horsepower` and `year` as features (variables).
-   Compute and comment on the RMSE.

```{r regression}
m1 <- lm(mpg ~ horsepower + year, data = Auto)
get_regression_summaries(m1)
```

> [Answer]{style="color:red;font-weight:bold"}: *Here we see that using a simple MLR model, our predictions of MPG are off by \~4.3 mpg on average (RMSE = 4.37).*

# Feature Engineering

-   Create 10 features based on the `name` column.
-   Remove all rows with a missing value.
-   Ensure only `mpg` and the engineered features remain.
-   Compute and comment on the RMSE.

```{r features}
auto_feat <- Auto %>%
  mutate(
    manufacturer = str_split(name, " ", simplify = TRUE)[,1],
    model_length = str_length(name),
    turbo = str_detect(tolower(name), "turbo"),
    diesel = str_detect(tolower(name), "diesel"),
    coupe = str_detect(tolower(name), "coupe"),
    v8 = str_detect(tolower(name), "v8"),
    sport = str_detect(tolower(name), "sport"),
    wagon = str_detect(tolower(name), "wagon"),
    weight_yr = weight*year
  ) %>%
  dummy_cols(select_columns = "manufacturer") %>%
  select(-name, -origin, -acceleration, -cylinders, -displacement) %>%
  drop_na()

# Regression with new features
m2 <- lm(mpg ~ ., data = auto_feat)
get_regression_summaries(m2)
```

> [Answer]{style="color:red;font-weight:bold"}: *Here we see that our model with engineered features results in better predictions of MPG with a RMSE of 2.52, however due to the large number of manufacturers I would be cautious about overfitting.*

# Classification

-   Use either of $K$-NN or Naive Bayes to predict whether an automobile is a `chevrolet` or a `honda`.
-   Explain your choice of technique.
-   Report on your Kappa value.

```{r classification}
# Filter and preprocess data
auto_clf <- Auto %>%
  filter(str_detect(name, "(?i)chevrolet|honda")) %>% 
  mutate(
    make = factor(
      ifelse(str_detect(name, "(?i)chevrolet"), "Chevrolet", "Honda"),
      levels = c("Chevrolet", "Honda")
    )
  ) %>%
  select(-name, -origin) %>%  
  drop_na()

# Split data
set.seed(505)
train_idx <- createDataPartition(auto_clf$make, p = 0.7, list = FALSE)
train <- auto_clf[train_idx, ]
test <- auto_clf[-train_idx, ]

# Preprocess
preproc <- preProcess(train %>% select(-make), method = c("center", "scale"))
train_processed <- predict(preproc, train)
test_processed <- predict(preproc, test)

# KNN with 10-fold CV and class weights
ctrl <- trainControl(
  method = "cv", 
  number = 10,  
  classProbs = TRUE,
  summaryFunction = defaultSummary
)

knn_model <- train(
  make ~ .,
  data = train_processed,
  method = "knn",
  tuneLength = 15,
  trControl = ctrl,
  metric = "Kappa"  
)

# Evaluate on test set
pred <- predict(knn_model, test_processed)
confusionMatrix(pred, test_processed$make)
```

> [Answer]{style="color:red;font-weight:bold"}: *I chose KNN for its ability to handle non-linear patterns and class imbalance, demonstrated by a strong Kappa value of 0.81. This highlights reliable performance in distinguishing Chevrolets from Hondas, even with imbalanced data, using scaled features like horsepower and weight.*

# Binary Classification

-   Predict whether a car is a `honda`.
-   Use model weights.
-   Display and comment on an ROC curve.

```{r binary classification}
auto_bin <- Auto %>%
  mutate(
    honda = factor(
      ifelse(str_detect(name, "(?i)honda"), "Honda", "NonHonda"),
      levels = c("NonHonda", "Honda") 
    )
  ) %>%
  select(-name, -origin) %>% 
  drop_na()

# Split data 
set.seed(505)
train_idx <- createDataPartition(auto_bin$honda, p = 0.7, list = FALSE)
train <- auto_bin[train_idx, ]
test <- auto_bin[-train_idx, ]

# Regularized Logistic Regression
ctrl <- trainControl(
  method = "cv",
  number = 5,
  classProbs = TRUE,
  summaryFunction = twoClassSummary,
  savePredictions = "final"
)

log_model <- train(
  honda ~ .,
  data = train,
  method = "glmnet",
  family = "binomial",
  tuneGrid = expand.grid(
    alpha = 1,  # Lasso penalty
    lambda = 10^seq(-4, 0.5, length = 20)  # Penalty strength
  ),
  trControl = ctrl,
  metric = "ROC"
)

# Evaluate on test set
prob_test <- predict(log_model, test, type = "prob")$Honda
roc_test <- roc(test$honda, prob_test)
plot(roc_test, main = "Test Set ROC (Regularized Model)")
cat("AUC:", auc(roc_test), "\n")

# Confusion Matrix (optimize threshold)
pred_test <- factor(ifelse(prob_test > 0.5, "Honda", "NonHonda"), 
                   levels = c("NonHonda", "Honda"))
confusionMatrix(pred_test, test$honda)
```

> [Answer]{style="color:red;font-weight:bold"}: *In the ROC curve we see this model has decent performance clearly better than random classification but not perfect. In previous iterations it displayed as a near perfect classifier but I had to tune my model as I believe it was overfitting.*

# Ethics

-   Based on your analysis, comment on the [Clean Air Act of 1970 and Ammendments of 1977](https://www.epa.gov/clean-air-act-overview/evolution-clean-air-act)
-   Discuss the civic reposibilities of data scientists for:
    -   Big Data and Human-Centered Computing
    -   Democratic Institutions
    -   Climate Change
-   Provide at least one statistical measure for each, such as a RMSE, Kappa value, or ROC curve.

> [Analysis]{style="color:green;font-weight:bold"}: The Clean Air Act and its amendments drove measurable improvements in fuel efficiency, as seen in the strong correlation between year and MPG (r = 0.58). However, post-1980 models showed a 30% increase in prediction error (RMSE), rising from 3.01 to 3.91. This suggests a trade-off: while emissions regulations improved average efficiency, they may have introduced variability in engineering practices (e.g., turbochargers, catalytic converters). Policymakers must balance standardization with innovation to avoid unintended unpredictability in environmental outcomes.

> **Big Data & Human-Centered Computing**  
> - **Responsibility**: Ensure transparency and equity in models impacting public policy.  
> - **Statistic**: **RMSE increased by 30.2%** post-1980 (3.01 → 3.91), highlighting reduced predictability in fuel efficiency. Transparent reporting of such variability prevents overconfidence in policy outcomes.  

```{r big data}
Auto <- Auto %>%
  mutate(
    year_2d = as.numeric(str_sub(as.character(year), -2))  # Extract last 2 digits (years were showing up in the 3800s)
  )
Auto_early <- Auto %>% filter(year_2d >= 77 & year_2d <= 79)  
Auto_late <- Auto %>% filter(year_2d >= 80)  

model_early <- lm(mpg ~ horsepower + weight, data = Auto_early)
model_late <- lm(mpg ~ horsepower + weight, data = Auto_late)

rmse_early <- get_regression_summaries(model_early)$rmse
rmse_late <- get_regression_summaries(model_late)$rmse

cat(
  "1977-1979 RMSE:", round(rmse_early, 2),
  "\n1980-1982 RMSE:", round(rmse_late, 2),
  "\nRMSE Change:", round((rmse_early - rmse_late)/rmse_early * 100, 1), "%"
)
```

> **Democratic Institutions**  
> - **Responsibility**: Advocate for data-driven policymaking and public accountability.  
> - **Statistic**: **Correlation ($r = 0.58$)** between year and MPG quantifies the Clean Air Act’s success in improving efficiency. Open data sharing fosters democratic trust.  

```{r democracy}
cor_test <- cor.test(Auto$year, Auto$mpg, method = "pearson")
cat("Correlation (Year vs. MPG): r =", round(cor_test$estimate, 2))
```

> **Climate Change**  
> - **Responsibility**: Prioritize accurate detection of high-emission vehicles.  
> - **Statistic**: **Kappa = 0.77** ensures reliable identification of high-emission cars, critical for enforcing emissions caps.  

```{r climate}
Auto <- Auto %>% 
  mutate(high_emission = factor(
    ifelse(mpg < quantile(mpg, 0.25), "High", "Low"),
    levels = c("Low", "High")
  ))
set.seed(505)
ctrl <- trainControl(method = "cv", number = 5)
knn_model <- train(
  high_emission ~ horsepower + weight + year,
  data = Auto,
  method = "knn",
  trControl = ctrl,
  metric = "Kappa"
)
cat("Kappa:", knn_model$results$Kappa[which.max(knn_model$results$Kappa)])
```
